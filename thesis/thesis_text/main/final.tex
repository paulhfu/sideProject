\chapter{Conclusion}\label{chap:conclus}
The latest successes of reinforcement learning methods justifies to think about transferring the concept to the field of statistical learning. This has been done in this work for the image segmentation task. One drawback of reinforcement learning methods is the requirement of large amounts of experience data which makes it not suitable for supervised learning where a common challenge is to achieve satisfactory results with the possibly least amount of training data.\\
Therefore unsupervised and self supervised learning becomes more attractive in this setting. Luckily reinforcement learning adds a lot flexibility by not requirering that the generation of the supervision signal is differentiable. Given enough prior knowledge a supervision signal can be created for simple objects quite easily. This works given there is a good enough projection into the embedding space of the raw data. For this projection function there still needs to be some ground truth present. However for the training of the embeddings significantly less ground truth is necessary. The proposed methods for training the embedding network from scatch in an unsupervised fashion have been tested to some extend with so far no noteworthy results.\\
The proposed setting also gives rise to transform a segmentation problem into a classification problem with generating rewards on object level by having a pretrained predictor that classifies images of single objects. The classification scores can then be used to generate a reward.\\
The intention in the starting phase of this work was of course to have a method working on "real" data for an existing problem and not only a toy problem. This intention turned out to go beyond the timeframe of this project. This among other things is reserved for future work on this topic.
