\chapter{Conclusion}\label{chap:conclus}
The latest successes of Reinforcement Learning methods justify to think about transferring the concept to tasks that are usually solved by methods of statistical learning. This has been done in this work for the image segmentation task. One drawback of reinforcement learning methods is the requirement of large amounts in experience data which makes it not suitable for supervised learning, where a common challenge is to achieve adequate results with the least possible amount of training data.\\
Therefore unsupervised and self supervised learning becomes more attractive in this setting. Luckily reinforcement learning adds a lot of flexibility by not requiring that the generation of the supervision signal is differentiable. Given enough prior knowledge, a sufficiently good reward signal can be created for simple objects quite easily. One restriction is the requirement of a pre-trained feature extractor. In this work a embedding network is used to project pixels into an embedding space. The training of the embedding network still requires some ground truth labels. The proposed methods for training the embedding network from scratch in an unsupervised fashion have been tested to some extend with so far no noteworthy results.\\
The proposed setting motivates to transform a segmentation problem into a classification problem where rewards are generated on object level using predictions of a pre trained network that classifies images of single objects. The classification scores can then be used to generate a reward for a given object proposal in the predicted segmentation.\\
The intention in the starting phase of this project was of course to have a method working on "real" data for an existing problem and not "only" on a toy data set. This intention turned out to go beyond the time frame of this project. This is, among other things, reserved for future work on this topic.
