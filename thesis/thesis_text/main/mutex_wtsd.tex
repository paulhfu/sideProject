\section{Obtaining superpixels from mutex watershed}~\label{seg:pip_mutex}
There are many algorithms that can be used to compute an superpixel segmentation. Mutex watershed \ref{sec:mtx_wtsd} is a very flexibly method because it relies on affinities and there are many methods to obtain those one of which are learned affinities. With the power of CNNs one can train quite easily a very generic affinity predictor. Globally scaling repulsive and/or attractive then allows for control over the granularity of the superpixel. In addition to that, mutex watershed is a comparatively fast algorithm under certain conditions that are mainly dependent on the amount of strong repulsive edges.\\
Having the segmentation image it is straight forward to generate a region adjacency graph from that.

\section{The embedding network}~\label{seg:pip_embed}

The embedding network was realized with a U-net architecture where the final layer outputs 16 channels. There are several ways to train the embedding network. If ground truth is available it can be trained prior to the SAC training with the contrastive loss \ref{ssec:loss_contrastive}.\\
If there is no ground truth there are three different bootstrapping procedures that can be included to the training of the SAC.\\
\begin{itemize}
 	\item The first one is the optimization of the embedding network through the RL losses. This is possible, because the masking of the embeddings by the superpixels followed by the averaging procedure is differentiable w.r.t. the embeddings. The embedding network forms one common feature extractor for actor and critic. Intuitively it should be more stable if it is optimized by only one of the two optimizers. Since the actor smoothes out variances and misspredictions in the Gibbs distribution of the critics prediction this should be the better choice.
 	\item The second procedure is a mixture of contrastive loss \ref{ssec:loss_contrastive} and triplet loss \ref{ssec:loss_triplet} based on the action predictions of the agent (defined by the mean of the predicted policy). Hereby all pixel embeddings belonging to the same superpixel should be close to each other in the embedding space. This is namely eq. (2.53) in \ref{ssec:loss_contrastive} where each superpixel corresponds to one cluster. For the inter pushing \emph{or} pulling "forces", triplet loss of the form of eq. (2.57) is used. The triplets can be found based on the action predictions of the agent. A positive superpixel pair is defined by the existence of a path of those superpixels in their region adjacency graph that has only action values on the edges that are below a certain threshold $tl$. On the contrary a negative pair is one that has at least one path between it where at least one action value on the edge is above a certain threshold $th$. Attractive paths between superixels in the region adjacency graph can be found by the Dijkstra's algorithm by setting all weights in the weighted adjacency matrix that are above $tl$ to $+\infty$ and then accepting all paths in the result that are not $+\infty$. In contrary, repulsive paths between superpixels can be found by setting all weights in the weighted adjacency matrix that are above $th$ to $+\infty$ and accepting all paths in the result that are $+\infty$. This method is visualized in figure \ref{figssss}. This selection of triplets does not protect from contradictions (see figure \ref{figsss}). To enforce a valid underlying segmentation, cycle constraints similar to eq. (2.36) in section \ref{sec:mtx_wtsd}.
 	\item The third method is in its result very similar to the second method, but here the triplet selection is based on the final segmentation $seg_t$. This methos does not have the problem of finding contradicting triples and is chosen in favor of the second method. However keep in mind, that this method is based on the sampled actions and not on the mean action of the policy as method two. To get the result based on the expected action an additional multicut can be obtained based on the expected actions.
\end{itemize}
Both procedures should happen intercheangably to the SAC training, where the optimization step frequency of the embedding network should be much lower and the loss should be over a "larger" mini batch considering the variance in the SAC predictions.