\section{Obtaining superpixels from mutex watershed}~\label{seg:pip_mutex}
There are many algorithms that can be used to compute a superpixel segmentation. Mutex Watershed (see section \ref{sec:mtx_wtsd}) is a very flexibly method because it relies on affinities and there are many methods to obtain those like learned affinities or directly based on pixel intensities.\\
With a CNN one can train a very generic affinity predictor. Globally scaling repulsive and/or attractive edge weights allows for control over the granularity of the superpixels. In addition to that, Mutex Watershed is a comparatively fast algorithm under certain conditions that are mainly dependent on the amount of strong repulsive edges.\\
Having the superpixel segmentation, it is straight forward to generate a region adjacency graph from that.

\section{The embedding network}~\label{seg:pip_embed}

The embedding network was realized with a U-Net architecture \cite{ronneberger2015unet} where the final layer outputs 16 channels. There are several ways to train the embedding network. If ground truth is available it can be trained prior to the SAC training with the contrastive loss \ref{ssec:loss_contrastive}.\\
If there is no ground truth there are three different bootstrapping procedures that can be included to the training of the SAC.\\
\begin{itemize}
 	\item The first one is the optimization of the embedding network through the RL losses. This is possible, because the masking of the embeddings by the superpixels followed by the averaging procedure is differentiable w.r.t. the pixel embeddings. The embedding network forms one common feature extractor for actor and critic. Intuitively it should be more stable if it is optimized only by one of the two optimizers. Since the actor smooths out variances and wrong probabilities in the Gibbs distribution of the critics prediction the better choice for optimizing the embedding network should be the backpropagated gradient of the actors loss function.
 	\item The second procedure is a mixture of contrastive loss \ref{ssec:loss_contrastive} and triplet loss \ref{ssec:loss_triplet} based on the action predictions of the agent (defined by the mean of the predicted policy). Hereby all pixel embeddings belonging to the same superpixel should be close to each other in the embedding space. This is namely eq. (2.53) in \ref{ssec:loss_contrastive} where each superpixel corresponds to one cluster.\\
 	For the inter pushing \emph{or} pulling forces, a triplet loss of the form in eq. (2.57) is used. The triplets can be found by evaluating the action predictions of the agent.\\
 	A positive superpixel pair is defined by the existence of a path between those superpixels in their region adjacency graph that has only action values on the edges that are below a certain threshold $tl$. On the contrary a negative pair is one that has at least one path between the two superpixels where at least one action value on the edge is above a certain threshold $th$.\\
 	Attractive paths between superixels in the region adjacency graph can be found with Dijkstra's algorithm by setting all weights (means of the action distributions) in the weighted adjacency matrix that are above $tl$ to $+\infty$ and then accepting all paths in the result that are not $+\infty$. In contrary, repulsive paths between superpixels can be found by setting all weights in the weighted adjacency matrix that are above $th$ to $+\infty$ and accepting all paths in the result that are $+\infty$. This selection of triplets does not protect from contradictions in the underlying segmentation. A valid underlying segmentation can be obtained by removing superpixel pairs that violate cycle constraints similar to eq. (2.36) in section \ref{sec:mtx_wtsd}.
 	\item The third method is in its result very similar to the second method, but here the triplet selection is based on the final segmentation $seg_t$. This method does not suffer from violated cycle constraints and is chosen in favor of the second method. However keep in mind, that this method is based on the sampled actions and not on the mean action of the policy as method two. To get the result based on the expected actions there needs to be an additional run of the Multicut algorithm.
\end{itemize}
The last two methods should happen interchangeably to the SAC training, where the optimization step frequency of the embedding network should be much lower and the loss should be over a "larger" mini batch considering the variance in early SAC predictions.