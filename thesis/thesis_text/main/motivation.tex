\chapter{Introduction}
\section{Motivation}~\label{chap:motivation}
Unsupervised learning is on a different level of causal modeling than supervised learning. In supervised learning the labels that are provided formulate an intermediate step between the knowledge of the causal connection between raw data and labels, and the application of that knowledge to a learning process. Getting rid of the label generation and directly apply the necessary knowledge to the learning process, as it is the case for unsupervised learning, would safe the whole expensive labeling process. In unsupervised learning the causal connection between raw data and ground truth is therefore directly modeled.\\
Unsupervised image segmentation algorithms like graphical models or clustering algorithms usually lack in incorporating semantic information in the image. Also classical training of CNNs is not fit for unsupervised learning because the computation that leads to the loss has to be differentiable. There are yet no methods to formulate prior knowledge in the form of constraints for size, shape, texture etc. as a differentiable loss term. Even simply formulating them, such that the formulations are exact and complete in the sense that the information in them is sufficient to describe the dependence between raw data and ground truth, is usually a hard task. However assuming the problem is easy enough and such formulations can be generated, it is still not clear how to train a neural network on such rules.\\
Reinforcement learning (RL) methods have the property that learning is based on temporal differences in rewards. Here the rewards can depend continuously on the parameters of the prediction model but do not have to. This means, that their generation does not have to be differentiable. Usually the rewards are obtained by measurements in a complex physical environment which is too difficult to model mathematically.\\
This property motivates to use RL in other learning problems such as the image segmentation problem.

\section{Contribution}
This work proposes an image segmentation pipeline based on RL and graph neural networks (GCN) where the level of supervision can be adjusted as needed. The pipeline has been tested on the toy problem of segmenting discs. It was tested in an almost unsupervised setting where the only supervision stems from the pretraining of a feature extractor network. The main training of the pipeline is usupervised where a non differentiable evaluation of the predictions is based on prior knowledge on the objects in the image.