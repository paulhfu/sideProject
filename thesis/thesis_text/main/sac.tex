\section{The actor critic networks}~\label{sec:sag_gcn}

In this section the involved GCNN's are discussed in detail. There is one network predicting the statistics for the policy. This is referred to as the actor network. Let the directed region adjacency graph of the superpixel segmentation be $G=(V,E)$. The conversion from the undirected region adjacency graph to a directed graph is achieved by replacing each undirected edge by a pair of opposing directed edges with the same incidental nodes. The implemented graph convolution on $G$ for $K$ convolution iterations is defined by the update functions\\

\begin{align}
\vec{e}_{ij}^{1} &= \sigma \left( \phi_0 \left(\vec{x}_i^{0}, \vec{x}_j^{0} \right)\right)\\
\vec{x}_i^1 &= \sigma \left( \gamma_0 \left(\vec{x}_i^0, \frac{1}{deg(\mathcal{N}(i))} \sum_{j \in \mathcal{N}(i)}  \vec{e}_{ij}^1 \right)\right)
\end{align}

For the first iteration as there are no edge features initially. The superscripts refer to the convolution step and $x_i^0$ is the node feature vector obtained by avaraging the pixel embeddings for each superpixel $i \in V$. 
$\phi^k$ and $\gamma^k$ are multi layer perceptrons at step $k$ and $\sigma$ is an elementwise non linear function.
$\vec{e}_{ij}^{k}$ is the edge feature vector at update step $k$ for edge $(ij) \in E$ where $i \in V$ is always the node index of the sink node and $j \in V$ the node index of the source node. $x_i^k$ is the node feature vector at update step $k$ for node $i \in V$.\\
The following $K-2$ iterations are defined by the update functions

\begin{align}
\vec{e}_{ij}^{k+1} &= \sigma \left( \phi_k \left(\vec{x}_i^k, \vec{x}_j^k, \vec{e}_{ij}^k \right)\right)\\
\vec{x}_i^{k+1} &= \sigma \left( \gamma_k \left(\vec{x}_i^k, \frac{1}{deg(\mathcal{N}(i))} \sum_{j \in \mathcal{N}(i)}  \vec{e}_{ij}^{k+1} \right) \right)\\
\text{for }k&=1...K-2
\end{align}

The final iteration is defined by the update function

\begin{align}
\vec{e}_{ij}^{K} &= \sigma \left( \phi_{K-1} \left(\vec{x}_i^{K-1}, \vec{x}_j^{K-1}, \vec{e}_{ij}^{K-1} \right)\right)
\end{align}

Where the the number of elements in the output vector $\vec{e}_{ij}^K$ corresponds to the number of the required scalar values that define the distribution used to describe the policy. For this pipeline, mean and variance of a Normal distribution are predicted.\\

The GCNNs approximating the state action values are referred to as the critic networks. There are two of them of equal architecture but distinct parameters, incorporating Double Q-Learning (see section \ref{text:doublQ}). The first convolution step in the critic network architecture is defined by the update step

\begin{align}
\vec{e}_{ij}^1 &= \sigma \left( \eta_0 \left(\vec{x}_i^0, \vec{x}_j^0, \vec{a}_{ij} \right)\right)\\
\vec{x}_i^1 &= \sigma \left( \psi_0 \left(\vec{x}_i, \frac{1}{deg(\mathcal{N}(i))} \sum_{j \in \mathcal{N}(i)}  \vec{e}_{ij}^1 \right)\right)
\end{align}
Where $\vec{a}_{ij}$ is the action $a_t$ corresponding to the edge $ij$ (and to the edge $ji$ in the digraph). $\eta^k$ and $\psi^k$
are multi layer perceptrons at update step $k$.
The following $M-2$ convolution steps are the updates

\begin{align}
\vec{e}_{ij}^{k+1} &= \sigma \left( \eta_k \left(\vec{x}_i^k, \vec{x}_j^k, \vec{e}_{ij}^k \right)\right)\\
\vec{x}_i^{k+1} &= \sigma \left( \psi_k \left(\vec{x}_i^k, \frac{1}{deg(\mathcal{N}(i))} \sum_{j \in \mathcal{N}(i)}  \vec{e}_{ij}^{k+1} \right)\right)\\
\text{for }k&=1...M-2
\end{align}
and the final iteration, again only updating edge features
\begin{align}
\vec{e}_{ij}^M &= \sigma \left( \eta_{M-1} \left(\vec{x}_i^{M-1}, \vec{x}_j^{M-1}, \vec{e}_{ij}^{M-1} \right)\right)
\end{align}

Following that, the graph $G$ with edge features $e_{ij}^M$ is split into unconnected subgraphs $SG=(SV,SE)$ such that each connected component in $SG$ is a subgraph in $G$ with exact $l$ edges and the union of all those subgraphs covers $G$ completely. It is continued with the edge features only because, for the state action value approximation, only information of affinities between superpixels is important. The first update on the subgraphs is defined by the update

\begin{align}
\vec{x}_i^1 &= \sigma \left( \beta_0 \left(\frac{1}{deg(\mathcal{N}(i))} \sum_{j \in \mathcal{N}(i)}  e_{ij}^M\right)\right)
\end{align}

With $ij\in SE$ where $i \in SV$ is always the node index of the sink node and $j \in SV$ the node index of the source node.
This is followed by the $N-2$ updates

\begin{align}
\vec{x}_i^{k+1} &= \sigma \left( \beta_k \left(\vec{x}_i^k, \frac{1}{deg(\mathcal{N}(i))} \sum_{j \in \mathcal{N}(i)}  \sigma \left( \delta_k \left(\vec{x}_i^k, \vec{x}_j^k\right)\right) \right)\right)\\
\text{for }k&=1...N-2
\end{align}

Again, $\delta^k$ and $\beta^k$ are multi layer perceptrons at step $k$. The last graph convolution iteration is the edge feature update

\begin{align}
\vec{e}_{ij} &= \sigma \left( \delta_{N-1} \left(\vec{x}_i^{N-1}, \vec{x}_j^{N-1} \right)\right)
\end{align}

the scalar state action value per subgraph $sg$ is obtained by

\begin{align}
	Q\pi(s_t, a_t)_{sg} = \gamma_{Q}\left( \frac{1}{l} \sum_{ij\in sg} \vec{e}_{ij} \right)
\end{align}

where $\gamma_{Q}$ is a multi layer perceptron outputting a scalar value. $\vec{e}_{ij}$ is dependent on $(s_t, a_t)$ by the introduced upstream pipelines in the way that $x^0_i$ depends on $s_t$ and the embedding network and $a_t$ are reparameterized samples from distributions dependent on the predicted statistics in eq. (3.8).