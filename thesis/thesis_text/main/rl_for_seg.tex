\section{Using RL for the image segmentation task}~\label{sec:rl_for_seg}

In this section the task of image segmentation is fit to the RL framework.\\
The agent takes the role of predicting action distributions where sampled actions perform some kind of change to the input of a segmentation algorithm. Rewards can be calculated from the resulting segmentation. The segmentation algorithm would therefore be part of the environment.\\
Common RL problems are usually problems that are easy to evaluate like determining the winner of a board game or evaluating a robots position relative to a target position. Also, often intermediate results are not rewarded at all or given a small negative reward in order to put pressure on the fast arrival at the final state.\\
In RL there is typically a physical environment that can be measured by some sensory devices. This measurements reflect the current state and a reward calculation based on that state can take place. For the task of image segmentation such an environment can not be found or measured.\\
The label predictions would have to be projected from the image plane into the "real world" where measurements could take place. Of course it is not clear how to do that, therefore the reward generation has to be based on a computational model of the environment. A predicted segmentation can only be evaluated if enough information on the objects within the input image is known a priori. E.g number of object instances per object class, position, texture, shape etc..\\
Given such an evaluation and given that the function that is optimized by the agent is capable of capturing the underlying probability distribution of data label pairs, the described RL setting is theoretically able to learn the task of image segmentation in a fully unsupervised way.\\

