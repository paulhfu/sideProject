\section{Using RL for the image segmentation task}~\label{sec:rl_for_seg}

The task of image segmentation fit generally into the RL framework. The agent takes the role of predicting action distribution where sampled actions perform some kind of change to the input of some clustering algorithm and the RL loss is calculated from the result of the cluster algorithm which is part of the environment. \\
The main advantage here is that the clustering algorithm does not need to be differentiable in order to optimize the agents parameters.\\
Common RL problems are usually problems that are easy to evaluate like determining the winner of a board game or evaluating a robots position relative to a target position. Also often intermediate results are not rewarded at all or given a small negative reward in order to put pressure on the fast arrival of the final state.\\
Typically in RL there is a phyiscal environment that can be explored by sensory input a reward evaluation can take place on that. The equivalent for the image segmentation task would be projecting the labels from the image plane into the 3d world and check if it labels all objects correctly. Of course this is highly infeasible therefore the reward generation has to be modeled by a virtual model of the environment. A segmentation can only be evaluated if enough information on the objects within the input image is known a priory. E.g number of object instances per object class, rough position, texture, shape etc.. \\
Given such an evaluation and given that the function that is optimized by the agent is capable of capturing the underlying probability distribution of data ground-truth tuples, the described RL setting is theoretically able to learn the task of segmentation in a fully unsupervised way.\\

