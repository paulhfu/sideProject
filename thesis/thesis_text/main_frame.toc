\babel@toc {USenglish}{}
\contentsline {chapter}{\numberline {1}Introduction}{6}{chapter.1}
\contentsline {section}{\numberline {1.1}Motivation}{6}{section.1.1}
\contentsline {section}{\numberline {1.2}Contribution}{6}{section.1.2}
\contentsline {chapter}{\numberline {2}Preliminaries}{7}{chapter.2}
\contentsline {section}{\numberline {2.1}Image segmentation}{7}{section.2.1}
\contentsline {section}{\numberline {2.2}Reinforcement learning (RL)}{8}{section.2.2}
\contentsline {subsection}{\numberline {2.2.1}Value functions}{10}{subsection.2.2.1}
\contentsline {subsection}{\numberline {2.2.2}Q-learning}{10}{subsection.2.2.2}
\contentsline {subsection}{\numberline {2.2.3}Policy gradient methods}{11}{subsection.2.2.3}
\contentsline {subsection}{\numberline {2.2.4}Maximum Entropy Reinforcement Learning}{12}{subsection.2.2.4}
\contentsline {subsection}{\numberline {2.2.5}Soft Actor-Critic (SAC)}{13}{subsection.2.2.5}
\contentsline {subsection}{\numberline {2.2.6}Common optimization methods}{14}{subsection.2.2.6}
\contentsline {section}{\numberline {2.3}Geometric deep learning}{16}{section.2.3}
\contentsline {section}{\numberline {2.4}Mutex watershed}{17}{section.2.4}
\contentsline {section}{\numberline {2.5}Image partitioning by multicuts}{19}{section.2.5}
\contentsline {section}{\numberline {2.6}Principal component analysis}{20}{section.2.6}
\contentsline {section}{\numberline {2.7}Loss functions}{21}{section.2.7}
\contentsline {subsection}{\numberline {2.7.1}Generalized dice loss}{21}{subsection.2.7.1}
\contentsline {subsection}{\numberline {2.7.2}Contrasive loss}{22}{subsection.2.7.2}
\contentsline {subsection}{\numberline {2.7.3}Triplet loss}{23}{subsection.2.7.3}
\contentsline {section}{\numberline {2.8}The reparameterization trick}{24}{section.2.8}
\contentsline {section}{\numberline {2.9}The Heugh transform}{25}{section.2.9}
\contentsline {chapter}{\numberline {3}Methods}{27}{chapter.3}
\contentsline {section}{\numberline {3.1}Using RL for the image segmentation task}{27}{section.3.1}
\contentsline {section}{\numberline {3.2}Using RL for predicting affinities}{27}{section.3.2}
\contentsline {section}{\numberline {3.3}Overview over the pipeline}{28}{section.3.3}
\contentsline {section}{\numberline {3.4}The pipeline in the RL terminology}{30}{section.3.4}
\contentsline {subsection}{\numberline {3.4.1}The state}{30}{subsection.3.4.1}
\contentsline {subsection}{\numberline {3.4.2}The actions}{30}{subsection.3.4.2}
\contentsline {subsection}{\numberline {3.4.3}The reward}{30}{subsection.3.4.3}
\contentsline {subsection}{\numberline {3.4.4}The agent}{31}{subsection.3.4.4}
\contentsline {subsection}{\numberline {3.4.5}The environment}{31}{subsection.3.4.5}
\contentsline {subsection}{\numberline {3.4.6}The problem of local optima}{31}{subsection.3.4.6}
\contentsline {subsection}{\numberline {3.4.7}Definition of the RL algorithm}{32}{subsection.3.4.7}
\contentsline {section}{\numberline {3.5}Obtaining superpixels from mutex watershed}{33}{section.3.5}
\contentsline {section}{\numberline {3.6}The embedding network}{33}{section.3.6}
\contentsline {section}{\numberline {3.7}The actor critic networks}{34}{section.3.7}
\contentsline {section}{\numberline {3.8}Finding subgraphs}{37}{section.3.8}
\contentsline {subsection}{\numberline {3.8.1}Thoughts on dependence}{38}{subsection.3.8.1}
\contentsline {section}{\numberline {3.9}Technical details}{39}{section.3.9}
\contentsline {subsection}{\numberline {3.9.1}Batch processing}{39}{subsection.3.9.1}
\contentsline {chapter}{\numberline {4}Experiments and results}{40}{chapter.4}
\contentsline {subsection}{\numberline {4.0.1}Supervised training}{41}{subsection.4.0.1}
\contentsline {subsection}{\numberline {4.0.2}Unsupervised training}{43}{subsection.4.0.2}
\contentsline {subsubsection}{Data conformity}{43}{subsubsection*.17}
\contentsline {chapter}{\numberline {5}Conclusion}{45}{chapter.5}
\contentsline {section}{References}{45}{section*.18}
