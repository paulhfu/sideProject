\section{The reparameterization trick} \label{ssec:reparam}
The reparameterization trick was proposed in \cite{kingma2013autoencoding}. Since then it is commonly used to make a sampling process, used to approximate an expectation, differentiable with respect to the statistics of the corresponding distribution. Not all distributions have definitions for their reparameterization yet but for some basic ones such as the normal distribution it is known.\\
The problem is stated as follows. Given a realization $y$ of a continuous random variable and its conditional distribution $y\sim q_{\theta}(y|x)$ where $\theta$ are the parameters of the distribution. Then the Monte Carlo estimate of the expectation $\mathbb{E}_{y \sim q_{\theta}(y|x)}[y] \approx \frac{1}{N}\sum_{n=0}^N y$ is not differentiable w.r.t. $\theta$, because the underlying sampling process, generating $y$ is not differentiable.\\

If a vector valued and differentiable function $g_{\theta}(\epsilon, x)$ where $\epsilon$ is an auxiliary variable distributed by $\epsilon \sim p(\epsilon)$, can be found such that $\mathbb{E}_{y\sim q_{\theta}(y|x)}[y] = \mathbb{E}_{\epsilon\sim p(\epsilon)}[g_{\theta}(\epsilon, x)]$ then the Monte Carlo estimate of the expectation $\mathbb{E}_{\epsilon\sim p(\epsilon)}[g_{\theta}(\epsilon, x)] \approx \frac{1}{N}\sum_{n=0}^N g_{\theta}(\epsilon_n, x)$ is differentiable w.r.t. $\theta$.\\

For the realization of a Normal distributed random variable $y \sim \mathcal{N}(\mu, \sigma^2)$ such a function would be

\begin{align}
	g(\epsilon, \mu, \sigma) = \frac{1}{\sigma}(\epsilon - \mu), \text{\hspace{8mm} $\epsilon \sim \mathcal{N}(0, 1)$}.
\end{align}

This is useful in RL since there is an expectation, approximated by the Monte Carlo estimate that needs to be differentiable with respect to the parameters of the policy from which actions are sampled from.