\section{Image segmentation}~\label{sec:prel_imagesegmentation}

Image segmentation or image partitioning is defined as the process of dividing a digital image into sets of pixels known as the objects in the image.\\
There are many variations concerning the segmentation method itself as well as the goal that is to be achieved. With the rise of CNNs, nowadays these methods are usually fully or by parts learning based. That means, that some parameterized function is optimized in order to approximate some target which can only be described by prior knowledge and/or by drawing samples from a target distribution. For the task of image segmentation these samples are of the form $(x, y)$ which is a realization of a random variable $(X, Y)$ with probability distribution $P_{X, Y}(x, y)$. Samples represent the raw input image $x$ that is to be segmented and the desired segmentation $y$ also referred to as label or label image. The goal is to learn a function $f(x)$ such that it approximates $\mathbb{E}[Y|X=x]$ at best. Since $P_{X, Y}$ is initially not known and only few samples and/or some prior knowledge on its properties are available, the approximation can only be achieved by the Monte Carlo estimate of the expectation obtained from those samples and by dexterous use of the prior knowledge. \\
Some of the variations of learning based methods for image segmentation are distinguished by their level of supervision during the optimization. This is mainly defined by the amount of data samples and prior knowledge on the distribution $P_{X, Y}$ that is available and used by the method.

\begin{itemize}
	\item \textbf{supervised segmentation} is the highest level of supervision. Here only samples from $P_{X, Y}$ are available to the method. If enough samples are available such that all regions in the domain of the distribution are covered sufficiently, this is usually all one needs to arrive at a satisfactory result. However for most applications the set of available samples is very limited.
	\item \textbf{unsupervised segmentation} is the lowest level of supervision. Here no samples from $P_{X, Y}$ are available to the method. The optimization method has to completely rely on prior knowledge on the underlying distribution. Realizations of $X$ are usually still available and can be used for the learning process.
	\item \textbf{semi-supervised segmentation} is the transition between the previous two. Similar to supervised learning, semi-supervised learning uses samples from $P_{X, Y}$, but not only. There are also realizations of $X$ available as well as some prior knowledge on $P_{X, Y}$ which is used for the learning process.
	\item \textbf{self-supervised learning} is usually referred to when the method generates some kind of supervisory signal for itself. E.g. an automated labeling procedure to generate sample approximations $(x, \bar{y})$. Self-supervised learning is a special case of unsupervised learning.
\end{itemize}

Other variations that focus more on the goal that should be achieved are

\begin{itemize}
	\item \textbf{semantic segmentation} is the process of assigning class labels to each pixel in the image. Different objects instances of the same class are labeled equally. Usually only some object classes of interest get a unique class label assigned to. All other object classes receive the label background.
	\item \textbf{instance segmentation} is similar to semantic segmentation in the sense that each pixel in the image is assigned a label to. This label attributes a pixel either to background or to an instance of an object class. Therefore different objects of the same class are labeled differently. Here the label of an instance is also referred to as object id.
	\item \textbf{panoptic segmentation} is a fusion of the previous two. For all pixels belonging to instances of some defined set of classes, instance segmentation is performed. For the remaining pixels, semantic segmentation without a background label is performed. The object instances for which instance segmentation is performed are referred to as "things" (objects with a well defined shape like cars, buildings ...) and the object instances for which semantic segmentation is performed are referred to as "stuff" (background regions like grass, sky ...).
\end{itemize}